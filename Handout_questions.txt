Q1. What is the total number of probabilities your robot has to keep
track of for a map of size m x n?

For each of the m x n intersections, there are 4 probabilities 
corresponding to the belief that the robot is at that intersection 
and facing one of the 4 directions. Therefore, we keep track of 
m x n x 4 probabilities. 

-------------------------------------------------------------------------
Q2. What should be the initial value of the probabilities your robot is
keeping track of?

The robot could start at any point on the map, so the initial values of the probabilities 
should be uniform. So the initial value of each probability should be 1/(m x n x 4).

-------------------------------------------------------------------------
Q3. Describe your strategy for dealing with sensor noise, and
explain why it should work and how you tested it.

1. Color sensor:
  i. To reduce noise, we implemented calibration for the color sensor. 
  For each color, we take 10 readings with different positions and 
  angle on the map. The result is stored in a file `colour_data.txt`. 
  Every time we detect the color, we get the 3 nearest neighbours and pick
  the mode color. This decreases missclassifications since there's a lower
  chance of picking an outlier vs when we initially only chose the closest neighbour.
  To deal with ambient light, we used a covering above the color sensor
  so that on average, the amount of ambient light would be the same.
  Finally, for dealing with sensor noise, each RGB value we use is an average of
  10 readings. This should decrease noise with the assumption of it being
  zero-mean Gaussian.
  
  We tested the colour sensor by getting readings above each colour, both in the
  center and on the edges of other colours, to get the accuracy of the sensor.

  ii. To further reduce the noise, when the color detection place a 
  relatively more important role, we will scan the color multiple times
  until the two consecutive readings are the same. We don't do this
  for every color detection because it takes longer time, and may not
  change status fast enough.

2. Gyro sensor & ultrasonic sensor:
  For the ultrasonic sensor, we have a margin of error so that as long
  as it reads within a couple mm within each other, we take the value.
  Similar to the ultrasonic sensor, the gyro sensor also has a margin of
  error for the angle that we accept. Both combined seemed to work well
  despite the noise since they seemed to have cancelled each other out.
  We tested it by rotating our colour sensor, which has the gyro sensor 
  on top and has the distance measured by the ultrasonic sensor.

-------------------------------------------------------------------------
Q4. Describe your probability update function in detail and
explain how you defined 'agreement' as well as how you
Determined the amount by which to update probabilities.

The probability update function assumes it is being called just after
the bot has drove forwards into an intersection (or reversed back if it
hit the border) and scanned it. It shifts beliefs by looking at each intersection
and making the belief that the bot is there facing up, the same as the old belief
that the bot was below this intersection facing up. It then does the same for every
other direction. The intersections on the edges of the map are more complex, how they
are handled is answered in Q6. The beliefs are normalized, then the function looks
at the colours seen at the last scan. For each colour, let's use the top-left as an
example, the program checks each intersection. It looks at each building at that
intersection, then looks at the direction the robot would have to be facing to see the 
building to it's top left. If the colour of the building matches the one scanned, it 
multiplies the belief by the chance the scan was right, if not, it multiplies
by the chance it was wrong. It then does this for all intersections, and all directions.

-------------------------------------------------------------------------
Q5. Describe in detail your robot's exploration strategy - it should
be more complex than simply moving in the same direction
until hitting the boundary of the map. How did you choose this
Strategy?

The bot will move forward, turn right and move forward, turn left and move forward,
then repeat until localization. Essentially, the bot moves in a diagonal to
hopefully hit multiple intersections before hitting the border. If the bot
does hit the edge, it reverses and turns right before moving along, to avoid 
cases where the bot gets stuck in a corner.

-------------------------------------------------------------------------
Q6. Describe in detail how beliefs are shifted when the robot gets
to a boundary. Consider this problem carefully, the correct
way to handle this is not obvious. Explain clearly what
assumptions regarding the robot's motion support your
strategy for shifting belief values in this case.

It is assumed that when the bot hits a boundry it reverses back to the
intersection it came from. Because of this, after the bot moves to an intersection,
the odds of it being on the bottom of the map, facing up, is zero, as it cannot move 
up from the border while facing up, so the belief is set to a very low value, just
incase there is some mistake. The bot being at the bottom, facing down, could be from it being
on the space above facing down, or from it hitting the border and reversing back up, so
the value of the facing down belief is the sum of those two beliefs. Simlar logic happens for 
all other borders.

-------------------------------------------------------------------------
Q7. Describe in detail how beliefs are shifted when the robot turns
90 degrees (either left or right) without going to a different
Intersection. Describe your assumptions about robot motion,
and how these support your strategy for handling this case.

When the robot turns 90 degrees, so do the beliefs at each intersection. For example
if the bot turns 90 degrees right, the 'up' belief at each intersection becomes 
the new 'right' belief. The 'right' belief becomes the new 'down' belief etc. And 
the same thing happens in the opposite direction when the bot turns left.
This strategy is used assuming the bot is able to turn without leaving the intersection
every time. If this is the case, then the odds the bot was facing up after the turn, are the same as the 
odds the bot was facing right before it, which is what the belief shifting was modelled after.

-------------------------------------------------------------------------
Q8. Explain your method for deciding when the robot has achieved
correct localization.

The robot has achieved correct localization when it's highest belief
is at least 0.6 higher than it's second highest belief. This was done so
that the highest belief not only had to be very large, but it also had
to be significantly larger than the second highest (and thus all the other beliefs),
avoiding having a very large threshold it may not reach, and also avoiding
a low threshold that it would take too early.

-------------------------------------------------------------------------
Q9. Briefly explain your robot design choices, including sensor placement
and robot mobility considerations.

We made a 2-wheel robot with a color sensor, gyro sensor and ultrasonic
sensor. The brick is on the top of the robot. The color sensor is placed in 
the front of the robot, and the  gyro placed right above the color sensor. 
The color sensor and gyro shares the same motor, so that we can detect both 
the angle rotated of the color sensor and the driving direction of the whole 
robot. We used several gears to connect sensors to the motor, which enables 
the sensors rotate in a range of 0 to 180 degrees. The ultrasonic sensor is 
put under the brick, aiming the centre of the robot, also represents the 
color sensor's position when it's 90 degrees i.e. facing the front. A shield 
is placed around the color sensor to avoid certain amount of the ambient light. 

We read colors by moving the robot forward until it sees yellow. First we scan 
the two bottom colors, then move forward a bit to scan the two top colors. 
This is also a reasonable position for us to turn because the robot is
relatively large. 

Because of the relative position of the brick, the color sensor and the gyro,
we should arrange the wires very carefully to avoid the motor for sensors 
being stuck.

-------------------------------------------------------------------------
Q10. What parameters did you find affect the most the ability of the robot to
determine its location?

Running into the border multiple times makes the robot have a hard time finding 
it's location, as does too many movement or scanning issues in a row.

-------------------------------------------------------------------------
Q11. Can external factors (illumination in the room, for example) affect the
ability of the robot to find itself?

They could, as they may result in the bot reading incorrect colours and thinking it is 
somewhere it is not. However, our calibration seems to work very well as reducing these
errors, and the localization algorithm can still find itself, even if a colour is read wrong 
every now and then.

-------------------------------------------------------------------------
Q12. On average, how many intersections does your robot need to visit
to achieve successful localization?

If it manages to stay away from the edges, the bot can localize in 2 or 3 intersection visits.

-------------------------------------------------------------------------
Q13. Are there locations in the map that make localization harder? (i.e.
does it matter where your robot starts its journey? Why?)

Most edges of the map seem to make localization harder, as the beliefs at the edge of the map
facing certian directions are more complex than any other point on the map.
The bottom left corner specifically seems to be a troubling point, as the intersections in that area
match up with others nearby, so colliding with the red on the edge may cause the bot to think it is 
somewhere else.

